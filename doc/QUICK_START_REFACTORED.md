# å¿«é€Ÿå¼€å§‹ - é‡æ„ç‰ˆ

## ğŸš€ å¯åŠ¨æœåŠ¡

### 1. å®‰è£…ä¾èµ–
```bash
pip install -r requirements_refactored.txt
```

### 2. é…ç½®ç¯å¢ƒï¼ˆå¯é€‰ï¼‰
```bash
cp env.example .env
# ç¼–è¾‘ .env æ–‡ä»¶ä¿®æ”¹é…ç½®
```

### 3. å¯åŠ¨æœåŠ¡
```bash
python app_refactored.py
```

æˆ–è€…ä½¿ç”¨uvicornï¼š
```bash
uvicorn app_refactored:app --host 0.0.0.0 --port 8000 --reload
```

### 4. è®¿é—®APIæ–‡æ¡£
æ‰“å¼€æµè§ˆå™¨è®¿é—®ï¼š
- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc
- è·¯ç”±è¡¨: http://localhost:8000/

## ğŸ“‹ è·¯ç”±è¡¨æ¦‚è§ˆ

### æ ¹è·¯å¾„
```bash
GET /
```
è¿”å›å®Œæ•´çš„è·¯ç”±è¡¨å’ŒAPIæ¦‚è§ˆ

### è®­ç»ƒæ¥å£
```bash
POST   /api/v2/training/start        # å¯åŠ¨è®­ç»ƒ
GET    /api/v2/training/{task_id}    # æŸ¥è¯¢çŠ¶æ€
GET    /api/v2/training/{task_id}/logs # è·å–æ—¥å¿—æµ
POST   /api/v2/training/{task_id}/stop # åœæ­¢è®­ç»ƒ
```

### æ¨ç†æ¥å£
```bash
POST   /api/v2/inference/start       # å¯åŠ¨æ¨ç†
POST   /api/v2/inference/batch       # æ‰¹é‡æ¨ç†
GET    /api/v2/inference/{task_id}   # æŸ¥è¯¢çŠ¶æ€
```

### ä»»åŠ¡ç®¡ç†
```bash
GET    /api/v2/tasks                 # æ‰€æœ‰ä»»åŠ¡
GET    /api/v2/tasks/{task_id}       # ä»»åŠ¡è¯¦æƒ…
GET    /api/v2/tasks/{task_id}/logs  # ä»»åŠ¡æ—¥å¿—
POST   /api/v2/tasks/{task_id}/cancel # å–æ¶ˆä»»åŠ¡
DELETE /api/v2/tasks/{task_id}       # åˆ é™¤ä»»åŠ¡
```

### èµ„æºç®¡ç†
```bash
GET    /api/v2/resources             # èµ„æºçŠ¶æ€
GET    /api/v2/resources/gpu         # GPUä¿¡æ¯
POST   /api/v2/resources/config      # æ›´æ–°é…ç½®
```

### ç³»ç»ŸçŠ¶æ€
```bash
GET    /api/v1/health                # å¥åº·æ£€æŸ¥
GET    /api/v1/info                  # ç³»ç»Ÿä¿¡æ¯
```

## ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹

### 1. å¯åŠ¨è®­ç»ƒä»»åŠ¡
```bash
curl -X POST "http://localhost:8000/api/v2/training/start" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "resnet18",
    "num_classes": 37,
    "train_path": "data/train",
    "val_path": "data/val",
    "save_path": "models/output",
    "batch_size": 16,
    "num_epochs": 50,
    "learning_rate": 0.0001,
    "device": "cuda",
    "priority": 5
  }'
```

å“åº”ï¼š
```json
{
  "task_id": "xxx-xxx-xxx",
  "task_type": "training",
  "status": "pending",
  "device": "cuda",
  "created_at": "2024-01-01T00:00:00"
}
```

### 2. æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
```bash
curl http://localhost:8000/api/v2/tasks/{task_id}
```

### 3. è·å–å®æ—¶æ—¥å¿—
```python
import requests

url = f"http://localhost:8000/api/v2/training/{task_id}/logs"
with requests.get(url, stream=True) as response:
    for line in response.iter_lines():
        if line:
            print(line.decode('utf-8'))
```

### 4. å¯åŠ¨æ¨ç†ä»»åŠ¡
```bash
curl -X POST "http://localhost:8000/api/v2/inference/start" \
  -H "Content-Type: application/json" \
  -d '{
    "cfg_path": "configs/model.yaml",
    "weight_path": "models/best.pth",
    "source_path": "data/test",
    "save_path": "results/",
    "device": "cuda"
  }'
```

### 5. æ‰¹é‡æ¨ç†
```bash
curl -X POST "http://localhost:8000/api/v2/inference/batch" \
  -H "Content-Type: application/json" \
  -d '{
    "cfg_path": "configs/model.yaml",
    "weight_path": "models/best.pth",
    "source_paths": [
      "data/test1",
      "data/test2",
      "data/test3"
    ],
    "device": "cuda"
  }'
```

### 6. æŸ¥çœ‹èµ„æºçŠ¶æ€
```bash
curl http://localhost:8000/api/v2/resources
```

å“åº”ï¼š
```json
{
  "device_usage": {
    "cuda": {
      "training": 1,
      "inference": 2
    }
  },
  "limits": {
    "cuda": {
      "training": 1,
      "inference": 3
    }
  },
  "gpu_info": {
    "available": true,
    "count": 1,
    "devices": [...]
  }
}
```

### 7. å¥åº·æ£€æŸ¥
```bash
curl http://localhost:8000/api/v1/health
```

### 8. å–æ¶ˆä»»åŠ¡
```bash
curl -X POST "http://localhost:8000/api/v2/tasks/{task_id}/cancel"
```

## ğŸ”§ é…ç½®è¯´æ˜

### ç¯å¢ƒå˜é‡
åœ¨ `.env` æ–‡ä»¶ä¸­é…ç½®ï¼š

```bash
# æœåŠ¡å™¨
HOST=0.0.0.0
PORT=8000
DEBUG=true

# èµ„æºé™åˆ¶
MAX_TRAINING_CONCURRENT_GPU=1    # GPUè®­ç»ƒä»»åŠ¡å¹¶å‘æ•°
MAX_INFERENCE_CONCURRENT_GPU=3   # GPUæ¨ç†ä»»åŠ¡å¹¶å‘æ•°
MAX_TRAINING_CONCURRENT_CPU=2    # CPUè®­ç»ƒä»»åŠ¡å¹¶å‘æ•°
MAX_INFERENCE_CONCURRENT_CPU=4   # CPUæ¨ç†ä»»åŠ¡å¹¶å‘æ•°
```

### è¿è¡Œæ—¶æ›´æ–°é…ç½®
```bash
curl -X POST "http://localhost:8000/api/v2/resources/config" \
  -H "Content-Type: application/json" \
  -d '{
    "max_concurrent": {
      "cuda": {
        "training": 2,
        "inference": 5
      }
    }
  }'
```

## ğŸ Pythonå®¢æˆ·ç«¯ç¤ºä¾‹

### å®‰è£…å®¢æˆ·ç«¯åº“
```bash
pip install requests
```

### ä½¿ç”¨ç¤ºä¾‹
```python
import requests
import time

# æœåŠ¡å™¨åœ°å€
BASE_URL = "http://localhost:8000"

# 1. å¯åŠ¨è®­ç»ƒ
response = requests.post(
    f"{BASE_URL}/api/v2/training/start",
    json={
        "model": "resnet18",
        "num_classes": 37,
        "train_path": "data/train",
        "val_path": "data/val",
        "save_path": "models/output",
        "batch_size": 16,
        "num_epochs": 50,
        "device": "cuda"
    }
)
task_id = response.json()["task_id"]
print(f"è®­ç»ƒä»»åŠ¡ID: {task_id}")

# 2. è½®è¯¢ä»»åŠ¡çŠ¶æ€
while True:
    response = requests.get(f"{BASE_URL}/api/v2/tasks/{task_id}")
    task = response.json()
    print(f"çŠ¶æ€: {task['status']}, è¿›åº¦: {task.get('progress', 0)}%")
    
    if task["status"] in ["completed", "failed", "cancelled"]:
        break
    
    time.sleep(5)

# 3. å¯åŠ¨æ¨ç†
response = requests.post(
    f"{BASE_URL}/api/v2/inference/start",
    json={
        "cfg_path": "configs/model.yaml",
        "weight_path": "models/best.pth",
        "source_path": "data/test",
        "device": "cuda"
    }
)
print(f"æ¨ç†ä»»åŠ¡ID: {response.json()['task_id']}")

# 4. æŸ¥çœ‹æ‰€æœ‰ä»»åŠ¡
response = requests.get(f"{BASE_URL}/api/v2/tasks")
tasks = response.json()
print(f"è®­ç»ƒä»»åŠ¡: {tasks['total_training']}")
print(f"æ¨ç†ä»»åŠ¡: {tasks['total_inference']}")
```

## ğŸ“Š ç›‘æ§å’Œæ—¥å¿—

### å®æ—¶æ—¥å¿—æµ
```python
import requests

task_id = "your-task-id"
url = f"http://localhost:8000/api/v2/training/{task_id}/logs"

with requests.get(url, stream=True) as response:
    for line in response.iter_lines():
        if line:
            # è§£æSSEæ ¼å¼
            if line.startswith(b'data: '):
                data = line[6:]  # ç§»é™¤ 'data: ' å‰ç¼€
                print(data.decode('utf-8'))
```

### Webç›‘æ§ç•Œé¢
```bash
# ä½¿ç”¨ä¹‹å‰çš„ web_monitor.html
# ä¿®æ”¹å…¶ä¸­çš„APIç«¯ç‚¹ä¸ºæ–°çš„è·¯ç”±
```

## ğŸ§ª æµ‹è¯•

### å¥åº·æ£€æŸ¥
```bash
curl http://localhost:8000/api/v1/health
```

### GPUçŠ¶æ€
```bash
curl http://localhost:8000/api/v2/resources/gpu
```

### ç³»ç»Ÿä¿¡æ¯
```bash
curl http://localhost:8000/api/v1/info
```

## ğŸ” æ•…éšœæ’æŸ¥

### æœåŠ¡æ— æ³•å¯åŠ¨
1. æ£€æŸ¥ç«¯å£æ˜¯å¦è¢«å ç”¨
2. æ£€æŸ¥ä¾èµ–æ˜¯å¦å®‰è£…å®Œæ•´
3. æŸ¥çœ‹é”™è¯¯æ—¥å¿—

### ä»»åŠ¡ä¸€ç›´æ’é˜Ÿ
1. æ£€æŸ¥èµ„æºçŠ¶æ€: `GET /api/v2/resources`
2. æŸ¥çœ‹æ˜¯å¦æœ‰ä»»åŠ¡å ç”¨èµ„æº
3. è°ƒæ•´å¹¶å‘é™åˆ¶é…ç½®

### GPUå†…å­˜ä¸è¶³
1. é™ä½batch_size
2. å‡å°‘GPUå¹¶å‘ä»»åŠ¡æ•°
3. ä½¿ç”¨CPUè¿›è¡Œæ¨ç†

## ğŸ“š æ›´å¤šæ–‡æ¡£

- [é¡¹ç›®ç»“æ„è¯´æ˜](REFACTORED_STRUCTURE.md) - è¯¦ç»†çš„æ¶æ„è¯´æ˜
- [APIæ–‡æ¡£](http://localhost:8000/docs) - å®Œæ•´çš„APIæ–‡æ¡£
- [é…ç½®è¯´æ˜](env.example) - ç¯å¢ƒå˜é‡è¯´æ˜

## ğŸ†š ä¸æ—§ç‰ˆæœ¬å¯¹æ¯”

### V2.2 â†’ V2.3 é‡æ„ç‰ˆ
âœ… ä»£ç ç»“æ„æ›´æ¸…æ™°
âœ… åˆ†å±‚æ›´æ˜ç¡®
âœ… æ›´æ˜“äºç»´æŠ¤å’Œæ‰©å±•
âœ… åŠŸèƒ½å®Œå…¨å…¼å®¹
âœ… æ€§èƒ½æ— æŸå¤±

### è¿ç§»æŒ‡å—
æ—§ç‰ˆç«¯ç‚¹ä»ç„¶å¯ç”¨ï¼Œæ–°ç‰ˆå»ºè®®ä½¿ç”¨ `/api/v2/*` ç«¯ç‚¹ã€‚

| æ—§ç‰ˆ | æ–°ç‰ˆ |
|------|------|
| `POST /train` | `POST /api/v2/training/start` |
| `POST /inference` | `POST /api/v2/inference/start` |
| `GET /task/{id}` | `GET /api/v2/tasks/{id}` |


