# GPUè®¾å¤‡é€‰æ‹©æŒ‡å—

## ğŸ¯ åŠŸèƒ½æ¦‚è¿°

RFUAV Model Service V2.3 æ”¯æŒçµæ´»çš„GPUè®¾å¤‡é€‰æ‹©ï¼š
- âœ… è‡ªåŠ¨æ£€æµ‹å¹¶æ˜¾ç¤ºæ‰€æœ‰å¯ç”¨GPU
- âœ… æ”¯æŒæŒ‡å®šå…·ä½“GPUè®¾å¤‡ï¼ˆcuda:0, cuda:1ç­‰ï¼‰
- âœ… æ”¯æŒè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜GPU
- âœ… å¤šGPUç¯å¢ƒä¸‹æ™ºèƒ½è´Ÿè½½å‡è¡¡
- âœ… å®æ—¶è¿½è¸ªæ¯ä¸ªGPUçš„ä»»åŠ¡æƒ…å†µ

## ğŸš€ å¯åŠ¨æ—¶GPUä¿¡æ¯

å¯åŠ¨æœåŠ¡æ—¶ä¼šè‡ªåŠ¨è¾“å‡ºGPUç¡¬ä»¶ä¿¡æ¯ï¼š

```bash
python app_refactored.py
```

è¾“å‡ºç¤ºä¾‹ï¼š
```
======================================================================
ğŸš€ GPUç¡¬ä»¶ä¿¡æ¯
======================================================================
âœ… GPUå¯ç”¨
ğŸ“¦ CUDAç‰ˆæœ¬: 11.8
ğŸ”§ PyTorchç‰ˆæœ¬: 2.0.1
ğŸ¯ æ£€æµ‹åˆ° 2 ä¸ªGPUè®¾å¤‡:

  GPU 0 (cuda:0)
  â”œâ”€ å‹å·: NVIDIA GeForce RTX 3090
  â”œâ”€ Compute Capability: 8.6
  â”œâ”€ æ€»æ˜¾å­˜: 24.00 GB
  â”œâ”€ å·²ç”¨æ˜¾å­˜: 0.50 GB (2.1%)
  â”œâ”€ ç©ºé—²æ˜¾å­˜: 23.50 GB
  â””â”€ å½“å‰ä»»åŠ¡: è®­ç»ƒ=0, æ¨ç†=0

  GPU 1 (cuda:1)
  â”œâ”€ å‹å·: NVIDIA GeForce RTX 3080
  â”œâ”€ Compute Capability: 8.6
  â”œâ”€ æ€»æ˜¾å­˜: 10.00 GB
  â”œâ”€ å·²ç”¨æ˜¾å­˜: 0.30 GB (3.0%)
  â”œâ”€ ç©ºé—²æ˜¾å­˜: 9.70 GB
  â””â”€ å½“å‰ä»»åŠ¡: è®­ç»ƒ=0, æ¨ç†=0

======================================================================
```

## ğŸ“‹ è®¾å¤‡é€‰æ‹©æ–¹å¼

### 1. è‡ªåŠ¨é€‰æ‹©ï¼ˆæ¨èï¼‰

ä½¿ç”¨ `cuda` ä¼šè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜GPUï¼š

```json
{
  "device": "cuda"
}
```

**ä¼˜åŠ¿**ï¼š
- ç³»ç»Ÿè‡ªåŠ¨é€‰æ‹©è´Ÿè½½æœ€å°çš„GPU
- é€‚åˆä¸å…³å¿ƒå…·ä½“GPUçš„åœºæ™¯
- è‡ªåŠ¨è´Ÿè½½å‡è¡¡

### 2. æŒ‡å®šå…·ä½“GPU

```json
{
  "device": "cuda:0"  // ä½¿ç”¨ç¬¬ä¸€å—GPU
}
```

```json
{
  "device": "cuda:1"  // ä½¿ç”¨ç¬¬äºŒå—GPU
}
```

**é€‚ç”¨åœºæ™¯**ï¼š
- éœ€è¦å›ºå®šä½¿ç”¨æŸå—GPU
- ç‰¹å®šæ¨¡å‹é€‚åˆç‰¹å®šGPU
- æ‰‹åŠ¨è´Ÿè½½å‡è¡¡

### 3. ä½¿ç”¨CPU

```json
{
  "device": "cpu"
}
```

**é€‚ç”¨åœºæ™¯**ï¼š
- æ²¡æœ‰GPU
- æµ‹è¯•å°æ¨¡å‹
- GPUèµ„æºç´§å¼ 

## ğŸ“ è®­ç»ƒæ—¶é€‰æ‹©GPU

### Pythonå®¢æˆ·ç«¯

```python
from test_refactored_api import RFUAVClient

client = RFUAVClient("http://localhost:8000")

# æ–¹å¼1: è‡ªåŠ¨é€‰æ‹©GPU
result = client.start_training(
    model="resnet18",
    num_classes=37,
    train_path="data/train",
    val_path="data/val",
    save_path="models/output",
    device="cuda"  # è‡ªåŠ¨é€‰æ‹©
)

# æ–¹å¼2: æŒ‡å®šGPU 0
result = client.start_training(
    model="resnet50",
    num_classes=37,
    train_path="data/train",
    val_path="data/val",
    save_path="models/output_gpu0",
    device="cuda:0"  # æŒ‡å®šGPU 0
)

# æ–¹å¼3: æŒ‡å®šGPU 1
result = client.start_training(
    model="vit_b_16",
    num_classes=37,
    train_path="data/train",
    val_path="data/val",
    save_path="models/output_gpu1",
    device="cuda:1"  # æŒ‡å®šGPU 1
)
```

### cURL

```bash
# è‡ªåŠ¨é€‰æ‹©
curl -X POST "http://localhost:8000/api/v2/training/start" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "resnet18",
    "num_classes": 37,
    "train_path": "data/train",
    "val_path": "data/val",
    "save_path": "models/output",
    "device": "cuda"
  }'

# æŒ‡å®šGPU 0
curl -X POST "http://localhost:8000/api/v2/training/start" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "resnet18",
    "num_classes": 37,
    "train_path": "data/train",
    "val_path": "data/val",
    "save_path": "models/output",
    "device": "cuda:0"
  }'
```

## ğŸ” æ¨ç†æ—¶é€‰æ‹©GPU

### Pythonå®¢æˆ·ç«¯

```python
# è‡ªåŠ¨é€‰æ‹©
result = client.start_inference(
    cfg_path="configs/model.yaml",
    weight_path="models/best.pth",
    source_path="data/test",
    device="cuda"
)

# æŒ‡å®šGPU 1
result = client.start_inference(
    cfg_path="configs/model.yaml",
    weight_path="models/best.pth",
    source_path="data/test",
    device="cuda:1"
)
```

### cURL

```bash
# æŒ‡å®šGPU 0
curl -X POST "http://localhost:8000/api/v2/inference/start" \
  -H "Content-Type: application/json" \
  -d '{
    "cfg_path": "configs/model.yaml",
    "weight_path": "models/best.pth",
    "source_path": "data/test",
    "device": "cuda:0"
  }'
```

## ğŸ“Š æŸ¥çœ‹GPUä½¿ç”¨æƒ…å†µ

### æŸ¥çœ‹èµ„æºçŠ¶æ€

```bash
curl http://localhost:8000/api/v2/resources
```

å“åº”ç¤ºä¾‹ï¼š
```json
{
  "device_usage": {
    "cuda:0": {
      "training": 1,
      "inference": 2
    },
    "cuda:1": {
      "training": 0,
      "inference": 1
    }
  },
  "active_tasks": {
    "cuda:0": [
      {"id": "task1", "type": "training"},
      {"id": "task2", "type": "inference"}
    ]
  },
  "limits": {
    "cuda:0": {
      "training": 1,
      "inference": 3
    }
  }
}
```

### æŸ¥çœ‹GPUè¯¦ç»†ä¿¡æ¯

```bash
curl http://localhost:8000/api/v2/resources/gpu
```

å“åº”ç¤ºä¾‹ï¼š
```json
{
  "available": true,
  "count": 2,
  "cuda_version": "11.8",
  "pytorch_version": "2.0.1",
  "devices": [
    {
      "id": 0,
      "device_name": "cuda:0",
      "name": "NVIDIA GeForce RTX 3090",
      "compute_capability": "8.6",
      "total_memory_gb": 24.0,
      "allocated_memory_gb": 8.5,
      "cached_memory_gb": 10.2,
      "free_memory_gb": 15.5,
      "utilization": 35.4,
      "current_tasks": {
        "training": 1,
        "inference": 2
      }
    },
    {
      "id": 1,
      "device_name": "cuda:1",
      "name": "NVIDIA GeForce RTX 3080",
      "compute_capability": "8.6",
      "total_memory_gb": 10.0,
      "allocated_memory_gb": 2.1,
      "cached_memory_gb": 3.5,
      "free_memory_gb": 7.9,
      "utilization": 21.0,
      "current_tasks": {
        "training": 0,
        "inference": 1
      }
    }
  ]
}
```

## ğŸ¯ æœ€ä½³å®è·µ

### 1. å•GPUç¯å¢ƒ

```python
# ä½¿ç”¨ cuda æˆ– cuda:0 éƒ½å¯ä»¥
device="cuda"  # æ¨è
device="cuda:0"  # ä¹Ÿå¯ä»¥
```

### 2. åŒGPUç¯å¢ƒ

**ç­–ç•¥1ï¼šè‡ªåŠ¨å‡è¡¡**
```python
# è®­ç»ƒå’Œæ¨ç†éƒ½ä½¿ç”¨è‡ªåŠ¨é€‰æ‹©
device="cuda"  # ç³»ç»Ÿè‡ªåŠ¨é€‰æ‹©è´Ÿè½½æœ€å°çš„GPU
```

**ç­–ç•¥2ï¼šè®­ç»ƒå’Œæ¨ç†åˆ†ç¦»**
```python
# è®­ç»ƒå›ºå®šåœ¨GPU 0
training_device = "cuda:0"

# æ¨ç†å›ºå®šåœ¨GPU 1
inference_device = "cuda:1"
```

**ç­–ç•¥3ï¼šå¤§å°æ¨¡å‹åˆ†ç¦»**
```python
# å¤§æ¨¡å‹ä½¿ç”¨æ˜¾å­˜å¤§çš„GPU
large_model_device = "cuda:0"  # å‡è®¾RTX 3090

# å°æ¨¡å‹ä½¿ç”¨æ˜¾å­˜å°çš„GPU
small_model_device = "cuda:1"  # å‡è®¾RTX 3080
```

### 3. å¤šGPUç¯å¢ƒï¼ˆ3+ï¼‰

**ç­–ç•¥ï¼šæŒ‰GPUèƒ½åŠ›åˆ†é…**
```python
# é«˜æ€§èƒ½GPUç”¨äºè®­ç»ƒ
training_devices = ["cuda:0", "cuda:1"]

# ä¸­ä½æ€§èƒ½GPUç”¨äºæ¨ç†
inference_devices = ["cuda:2", "cuda:3"]
```

## ğŸ”§ é«˜çº§é…ç½®

### è°ƒæ•´æ¯ä¸ªGPUçš„å¹¶å‘é™åˆ¶

```bash
curl -X POST "http://localhost:8000/api/v2/resources/config" \
  -H "Content-Type: application/json" \
  -d '{
    "max_concurrent": {
      "cuda:0": {
        "training": 1,
        "inference": 4
      },
      "cuda:1": {
        "training": 2,
        "inference": 6
      }
    }
  }'
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. æ˜¾å­˜ç®¡ç†

**å¤§æ¨¡å‹è®­ç»ƒ**ï¼š
```python
# ä½¿ç”¨æ˜¾å­˜æœ€å¤§çš„GPU
device = "cuda:0"  # å‡è®¾æ˜¯24GBçš„RTX 3090
batch_size = 32
```

**å°æ‰¹æ¬¡æ¨ç†**ï¼š
```python
# å¯ä»¥åœ¨ä»»ä½•GPUä¸Šè¿è¡Œ
device = "cuda"  # è‡ªåŠ¨é€‰æ‹©
batch_size = 8
```

### 2. å¹¶å‘æ§åˆ¶

**å•GPUå¤šä»»åŠ¡**ï¼š
- è®­ç»ƒï¼š1ä¸ªä»»åŠ¡ï¼ˆå ç”¨å¤§é‡æ˜¾å­˜ï¼‰
- æ¨ç†ï¼š3-5ä¸ªä»»åŠ¡ï¼ˆæ˜¾å­˜å ç”¨å°ï¼‰

**å¤šGPUè´Ÿè½½å‡è¡¡**ï¼š
```python
# è®­ç»ƒä»»åŠ¡
train_tasks = [
    {"device": "cuda:0", ...},
    {"device": "cuda:1", ...},
]

# æ¨ç†ä»»åŠ¡è‡ªåŠ¨åˆ†é…
infer_tasks = [
    {"device": "cuda", ...},  # ç³»ç»Ÿè‡ªåŠ¨é€‰æ‹©
    {"device": "cuda", ...},
]
```

### 3. é¿å…æ˜¾å­˜ç¢ç‰‡

**å»ºè®®**ï¼š
- åŒç±»å‹ä»»åŠ¡æ”¾åœ¨åŒä¸€GPU
- é¿å…é¢‘ç¹åˆ‡æ¢è®¾å¤‡
- å®šæœŸæ¸…ç†å®Œæˆçš„ä»»åŠ¡

## ğŸ› æ•…éšœæ’æŸ¥

### é—®é¢˜1ï¼šæŒ‡å®šçš„GPUä¸å­˜åœ¨

**é”™è¯¯**ï¼š
```
RuntimeError: Device index 2 is out of range
```

**è§£å†³**ï¼š
```bash
# æŸ¥çœ‹å¯ç”¨GPUæ•°é‡
curl http://localhost:8000/api/v2/resources/gpu

# ä½¿ç”¨æ­£ç¡®çš„è®¾å¤‡ç¼–å·ï¼ˆä»0å¼€å§‹ï¼‰
device = "cuda:0"  # æˆ– "cuda:1"
```

### é—®é¢˜2ï¼šGPUæ˜¾å­˜ä¸è¶³

**é”™è¯¯**ï¼š
```
RuntimeError: CUDA out of memory
```

**è§£å†³**ï¼š
```python
# æ–¹æ¡ˆ1ï¼šé™ä½batch_size
batch_size = 8  # ä»16é™åˆ°8

# æ–¹æ¡ˆ2ï¼šä½¿ç”¨æ˜¾å­˜æ›´å¤§çš„GPU
device = "cuda:0"  # åˆ‡æ¢åˆ°24GBçš„GPU

# æ–¹æ¡ˆ3ï¼šä½¿ç”¨CPU
device = "cpu"
```

### é—®é¢˜3ï¼šGPUè¢«å ç”¨

**ç°è±¡**ï¼šä»»åŠ¡ä¸€ç›´æ’é˜Ÿ

**æ£€æŸ¥**ï¼š
```bash
# æŸ¥çœ‹GPUä½¿ç”¨æƒ…å†µ
curl http://localhost:8000/api/v2/resources

# æŸ¥çœ‹æ´»åŠ¨ä»»åŠ¡
curl http://localhost:8000/api/v2/tasks
```

**è§£å†³**ï¼š
```python
# æ–¹æ¡ˆ1ï¼šä½¿ç”¨å…¶ä»–GPU
device = "cuda:1"

# æ–¹æ¡ˆ2ï¼šç­‰å¾…ä»»åŠ¡å®Œæˆ

# æ–¹æ¡ˆ3ï¼šå–æ¶ˆä¸å¿…è¦çš„ä»»åŠ¡
curl -X POST "http://localhost:8000/api/v2/tasks/{task_id}/cancel"
```

## ğŸ’¡ å®æˆ˜ç¤ºä¾‹

### ç¤ºä¾‹1ï¼šå¤šæ¨¡å‹å¹¶è¡Œè®­ç»ƒ

```python
client = RFUAVClient()

# åœ¨GPU 0ä¸Šè®­ç»ƒResNet
task1 = client.start_training(
    model="resnet50",
    num_classes=37,
    train_path="data/train",
    val_path="data/val",
    save_path="models/resnet50",
    device="cuda:0"
)

# åœ¨GPU 1ä¸Šè®­ç»ƒViT
task2 = client.start_training(
    model="vit_b_16",
    num_classes=37,
    train_path="data/train",
    val_path="data/val",
    save_path="models/vit",
    device="cuda:1"
)

print(f"ResNetè®­ç»ƒä»»åŠ¡: {task1['task_id']}")
print(f"ViTè®­ç»ƒä»»åŠ¡: {task2['task_id']}")
```

### ç¤ºä¾‹2ï¼šè®­ç»ƒ+æ¨ç†åŒæ—¶è¿›è¡Œ

```python
# åœ¨GPU 0ä¸Šè®­ç»ƒ
training_task = client.start_training(
    model="resnet18",
    device="cuda:0",
    ...
)

# åœ¨GPU 1ä¸Šæ¨ç†ï¼ˆä½¿ç”¨å·²è®­ç»ƒçš„æ¨¡å‹ï¼‰
inference_task = client.start_inference(
    cfg_path="configs/trained_model.yaml",
    weight_path="models/trained.pth",
    source_path="data/test",
    device="cuda:1"
)
```

### ç¤ºä¾‹3ï¼šæ‰¹é‡æ¨ç†è´Ÿè½½å‡è¡¡

```python
# è‡ªåŠ¨åˆ†é…åˆ°ä¸åŒGPU
test_paths = [
    "data/test1",
    "data/test2",
    "data/test3",
    "data/test4"
]

tasks = []
for path in test_paths:
    task = client.start_inference(
        cfg_path="configs/model.yaml",
        weight_path="models/best.pth",
        source_path=path,
        device="cuda"  # è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜GPU
    )
    tasks.append(task)

print(f"å·²å¯åŠ¨ {len(tasks)} ä¸ªæ¨ç†ä»»åŠ¡")
```

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [å¿«é€Ÿå¼€å§‹](QUICK_START_REFACTORED.md)
- [APIè·¯ç”±è¡¨](API_ROUTES_TABLE.md)
- [é¡¹ç›®ç»“æ„](REFACTORED_STRUCTURE.md)
- [èµ„æºç®¡ç†API](API_ROUTES_TABLE.md#èµ„æºç®¡ç†æ¥å£)

---

## ğŸ‰ æ€»ç»“

GPUè®¾å¤‡é€‰æ‹©åŠŸèƒ½ç‰¹ç‚¹ï¼š
- âœ… ç®€å•æ˜“ç”¨ - æ”¯æŒè‡ªåŠ¨é€‰æ‹©å’Œæ‰‹åŠ¨æŒ‡å®š
- âœ… æ™ºèƒ½è°ƒåº¦ - è‡ªåŠ¨é€‰æ‹©è´Ÿè½½æœ€å°çš„GPU
- âœ… çµæ´»é…ç½® - æ”¯æŒè¿è¡Œæ—¶è°ƒæ•´
- âœ… å®æ—¶ç›‘æ§ - éšæ—¶æŸ¥çœ‹GPUä½¿ç”¨æƒ…å†µ
- âœ… å¤šGPUæ”¯æŒ - å……åˆ†åˆ©ç”¨æ‰€æœ‰GPUèµ„æº

å¼€å§‹ä½¿ç”¨GPUè®¾å¤‡é€‰æ‹©ï¼Œè®©æ‚¨çš„æ·±åº¦å­¦ä¹ ä»»åŠ¡æ›´é«˜æ•ˆï¼ğŸš€


