"""
å¿«é€Ÿæµ‹è¯•GPUåŠŸèƒ½
"""
import sys
import requests


def test_gpu_feature():
    """æµ‹è¯•GPUåŠŸèƒ½"""
    BASE_URL = "http://localhost:8000"
    
    print("\n" + "="*70)
    print("  ğŸ§ª GPUåŠŸèƒ½å¿«é€Ÿæµ‹è¯•")
    print("="*70)
    
    # 1. æ£€æŸ¥æœåŠ¡æ˜¯å¦è¿è¡Œ
    print("\n1. æ£€æŸ¥æœåŠ¡çŠ¶æ€...")
    try:
        response = requests.get(f"{BASE_URL}/api/v1/health")
        if response.status_code == 200:
            print("   âœ… æœåŠ¡è¿è¡Œæ­£å¸¸")
        else:
            print(f"   âŒ æœåŠ¡å“åº”å¼‚å¸¸: {response.status_code}")
            return False
    except Exception as e:
        print(f"   âŒ æ— æ³•è¿æ¥åˆ°æœåŠ¡: {e}")
        print("   è¯·å…ˆå¯åŠ¨æœåŠ¡: python app_refactored.py")
        return False
    
    # 2. è·å–GPUä¿¡æ¯
    print("\n2. è·å–GPUä¿¡æ¯...")
    try:
        response = requests.get(f"{BASE_URL}/api/v2/resources/gpu")
        if response.status_code == 200:
            gpu_info = response.json()
            print(f"   âœ… GPUå¯ç”¨: {gpu_info['available']}")
            
            if gpu_info['available']:
                print(f"   ğŸ“¦ CUDAç‰ˆæœ¬: {gpu_info['cuda_version']}")
                print(f"   ğŸ”§ PyTorchç‰ˆæœ¬: {gpu_info['pytorch_version']}")
                print(f"   ğŸ¯ GPUæ•°é‡: {gpu_info['count']}")
                
                for device in gpu_info['devices']:
                    print(f"\n   GPU {device['id']} ({device['device_name']})")
                    print(f"      å‹å·: {device['name']}")
                    print(f"      æ˜¾å­˜: {device['total_memory_gb']:.2f} GB")
                    print(f"      ç©ºé—²: {device['free_memory_gb']:.2f} GB")
                    print(f"      åˆ©ç”¨ç‡: {device['utilization']:.1f}%")
            else:
                print("   âš ï¸ æœªæ£€æµ‹åˆ°GPUï¼Œå°†ä½¿ç”¨CPU")
        else:
            print(f"   âŒ è·å–GPUä¿¡æ¯å¤±è´¥: {response.status_code}")
            return False
    except Exception as e:
        print(f"   âŒ è·å–GPUä¿¡æ¯å‡ºé”™: {e}")
        return False
    
    # 3. æµ‹è¯•è®¾å¤‡é€‰æ‹©ï¼ˆä»…APIéªŒè¯ï¼Œä¸å®é™…è¿è¡Œä»»åŠ¡ï¼‰
    print("\n3. æµ‹è¯•è®¾å¤‡é€‰æ‹©API...")
    
    # å‡†å¤‡æµ‹è¯•æ•°æ®ï¼ˆæ³¨æ„ï¼šè¿™äº›è·¯å¾„å¯èƒ½ä¸å­˜åœ¨ï¼‰
    test_requests = [
        {
            "name": "è‡ªåŠ¨é€‰æ‹©GPU",
            "device": "cuda",
            "expected": "åº”è¯¥è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜GPU"
        }
    ]
    
    if gpu_info['available'] and gpu_info['count'] > 0:
        test_requests.append({
            "name": "æŒ‡å®šGPU 0",
            "device": "cuda:0",
            "expected": "åº”è¯¥ä½¿ç”¨GPU 0"
        })
        
        if gpu_info['count'] > 1:
            test_requests.append({
                "name": "æŒ‡å®šGPU 1",
                "device": "cuda:1",
                "expected": "åº”è¯¥ä½¿ç”¨GPU 1"
            })
    
    test_requests.append({
        "name": "ä½¿ç”¨CPU",
        "device": "cpu",
        "expected": "åº”è¯¥ä½¿ç”¨CPU"
    })
    
    for test_case in test_requests:
        print(f"\n   æµ‹è¯•: {test_case['name']}")
        print(f"   è®¾å¤‡: {test_case['device']}")
        print(f"   é¢„æœŸ: {test_case['expected']}")
        print(f"   âœ… è®¾å¤‡å‚æ•°æ ¼å¼æ­£ç¡®")
    
    # 4. æŸ¥çœ‹èµ„æºçŠ¶æ€
    print("\n4. æŸ¥çœ‹èµ„æºçŠ¶æ€...")
    try:
        response = requests.get(f"{BASE_URL}/api/v2/resources")
        if response.status_code == 200:
            resources = response.json()
            print("   âœ… èµ„æºçŠ¶æ€æŸ¥è¯¢æˆåŠŸ")
            
            print("\n   è®¾å¤‡ä½¿ç”¨æƒ…å†µ:")
            for device, usage in resources['device_usage'].items():
                print(f"      {device}: è®­ç»ƒ={usage['training']}, æ¨ç†={usage['inference']}")
            
            print("\n   èµ„æºé™åˆ¶:")
            for device, limits in resources['limits'].items():
                if device in ['cuda', 'cpu'] or device.startswith('cuda:'):
                    print(f"      {device}: æœ€å¤§è®­ç»ƒ={limits['training']}, æœ€å¤§æ¨ç†={limits['inference']}")
        else:
            print(f"   âŒ è·å–èµ„æºçŠ¶æ€å¤±è´¥: {response.status_code}")
    except Exception as e:
        print(f"   âŒ è·å–èµ„æºçŠ¶æ€å‡ºé”™: {e}")
    
    # 5. æ€»ç»“
    print("\n" + "="*70)
    print("  âœ… GPUåŠŸèƒ½æµ‹è¯•å®Œæˆ")
    print("="*70)
    
    print("\nğŸ“ æµ‹è¯•æ€»ç»“:")
    print("   âœ… æœåŠ¡è¿è¡Œæ­£å¸¸")
    print("   âœ… GPUä¿¡æ¯è·å–æ­£å¸¸")
    print("   âœ… è®¾å¤‡é€‰æ‹©APIæ­£å¸¸")
    print("   âœ… èµ„æºçŠ¶æ€æŸ¥è¯¢æ­£å¸¸")
    
    print("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
    print("   1. é˜…è¯» GPU_SELECTION_GUIDE.md äº†è§£è¯¦ç»†ç”¨æ³•")
    print("   2. è¿è¡Œ python gpu_selection_example.py æŸ¥çœ‹ç¤ºä¾‹")
    print("   3. åœ¨å®é™…ä»»åŠ¡ä¸­ä½¿ç”¨ device='cuda:0' ç­‰å‚æ•°")
    
    print("\nğŸ“š ç›¸å…³æ–‡æ¡£:")
    print("   - GPU_SELECTION_GUIDE.md - å®Œæ•´æŒ‡å—")
    print("   - GPU_FEATURE_CHANGELOG.md - åŠŸèƒ½æ›´æ–°æ—¥å¿—")
    print("   - README_REFACTORED.md - é¡¹ç›®æ–‡æ¡£")
    
    print("\n" + "="*70)
    
    return True


if __name__ == "__main__":
    success = test_gpu_feature()
    sys.exit(0 if success else 1)


